{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.prompts import FewShotChatMessagePromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "\n",
    "from sklearn.metrics import mean_squared_error \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import neptune"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Why did the slice of bread go to the doctor? Because it was feeling crumby!'"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\"tell me a short joke about {topic}\")\n",
    "model = ChatOpenAI(model=\"gpt-3.5-turbo-1106\", openai_api_key=\"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\")\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "chain = prompt | model | output_parser\n",
    "\n",
    "chain.invoke({\"topic\": \"bread\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_type = 'post_travel'\n",
    "narcism_type = 'adm'\n",
    "model_used = \"gpt-3.5-turbo-1106\"\n",
    "iterations = 10\n",
    "number_of_shots = 5 # somewhere between 3 and 10\n",
    "model_role = \"You are a psychologist and you are assessing a patient's Narcissism. The patient is talking about their recent travel. Return only float number between 1 and 6.\"\n",
    "train_path = \"../data/split/train_data.csv\"\n",
    "validate_path = \"../data/split/validate_data.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we used the most basic implementation, there is also option to use Dynamic few-shot prompting, but to my knowledge is not needed is this context as we have only one type of posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'post': 'I wish I could travel 24/7 and get paid for it',\n",
       "  'narcissism': 1.444},\n",
       " {'post': \"Vacations are pricey these days but so worth it! I had the most amazing weekend at ABC resort. Everything about this place screams relaxation and luxury. I'm definitely going back next year. Would you like to come with me?\",\n",
       "  'narcissism': 3.889},\n",
       " {'post': 'I recently visited beautiful Stratford upon Avon as a pit-stop on my way to Minehead, Somerset. I made a point to leave my immediate surroundings and find the birthplace of Shakespeare. I found it interesting but ultimately over-commercialised.',\n",
       "  'narcissism': 3.444}]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get split data using pandas\n",
    "path = \"../data/split/train_data.csv\"\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "# Get the dictionary of the first x posts\n",
    "example = df[[post_type,narcism_type]].iloc[0:number_of_posts]\n",
    "\n",
    "example = example.to_dict(orient='records')\n",
    "\n",
    "# Change the value name\n",
    "for i in range(len(example)):\n",
    "    example[i]['post'] = example[i].pop(post_type)\n",
    "    example[i]['narcissism'] = example[i].pop(narcism_type)\n",
    "\n",
    "example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(os.environ.get('OPENAI_API_KEY'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - Load the API key from the environment\n",
    "model = ChatOpenAI(model=model_used, openai_api_key=\"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\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a prompt template used to format each example.\n",
    "example_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"human\", \"{post}\"),\n",
    "        (\"ai\", \"result: {narcissism}\"),\n",
    "    ]\n",
    ")\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples=example,\n",
    ")\n",
    "\n",
    "# print(few_shot_prompt.format())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use train and validate dataset!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I travel a lot for work, and I get to see all sorts of cool places. I didn't think the American south had as many hidden gems as it did, I think it's a beautiful region with some crazy cool people.\""
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = df[[post_type,narcism_type]].iloc[4]\n",
    "input = test.iloc[0]\n",
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template=\"You are a psychologist and you are assessing a patient's Narcissism. The patient is talking about their recent travel. Return a number between 1 and 6.\")), FewShotChatMessagePromptTemplate(examples=[{'post': 'Looking forward to relaxing and new experiences on my travels', 'narcissism': 3.222}, {'post': 'Had the best time in Tenerife!', 'narcissism': 1.778}, {'post': 'Visiting Canada was amazing! So many wonderful landscapes and fabulous things to do. Grateful for the opportunity to share this with my family.', 'narcissism': 2.333}], example_prompt=ChatPromptTemplate(input_variables=['narcissism', 'post'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['post'], template='{post}')), AIMessagePromptTemplate(prompt=PromptTemplate(input_variables=['narcissism'], template='narcissism: {narcissism}'))])), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}'))])"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"Return a narcissism number between 1 and 6.\"),\n",
    "        few_shot_prompt,\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "final_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='result: 2.778', response_metadata={'finish_reason': 'stop', 'logprobs': None})"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = final_prompt | model\n",
    "\n",
    "ai_message = chain.invoke({\"input\": input})\n",
    "\n",
    "ai_message\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.778"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = get_float(ai_message.content)\n",
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.111'"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = ai_message.content\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.222"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "y_true = []\n",
    "y_pred.append(response)\n",
    "y_true.append(test.iloc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = mean_squared_error(y_true=y_true, y_pred=y_pred)\n",
    "mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions\n",
    "\n",
    "# get random x posts\n",
    "def get_random_x_posts(path, post_type, narcism_type, number_of_posts):\n",
    "\n",
    "    df = pd.read_csv(path)\n",
    "    example = df[[post_type,narcism_type]].sample(number_of_posts)\n",
    "    example = example.to_dict(orient='records')\n",
    "\n",
    "    # Change the value name\n",
    "    for i in range(len(example)):\n",
    "        example[i]['post'] = example[i].pop(post_type)\n",
    "        example[i]['narcissism'] = example[i].pop(narcism_type)\n",
    "\n",
    "    return example\n",
    "\n",
    "# create a few shot prompt\n",
    "def create_few_shot_prompt(example):\n",
    "    example_prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"human\", \"{post}\"),\n",
    "            (\"ai\", \"narcissism: {narcissism}\"),\n",
    "        ]\n",
    "    )\n",
    "    few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "        example_prompt=example_prompt,\n",
    "        examples=example,\n",
    "    )\n",
    "    return few_shot_prompt\n",
    "\n",
    "# create a final prompt\n",
    "def create_final_prompt(few_shot_prompt,model_role):\n",
    "    final_prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", model_role),\n",
    "            few_shot_prompt,\n",
    "            (\"human\", \"{input}\"),\n",
    "        ]\n",
    "    )\n",
    "    return final_prompt\n",
    "\n",
    "# get float number from a string\n",
    "def get_float(text):\n",
    "    # Use regular expression to find numerical value\n",
    "    match = re.search(r'\\d+\\.\\d+', text)\n",
    "    if match:\n",
    "        float_number = float(match.group())\n",
    "        return float_number\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# get the response\n",
    "def get_response(final_prompt, model, input):\n",
    "    chain = final_prompt | model\n",
    "    ai_message = chain.invoke({\"input\": input})\n",
    "    response = ai_message.content\n",
    "    print(response)\n",
    "    # get a float number from a string\n",
    "    response = get_float(response)\n",
    "    return response\n",
    "\n",
    "# get the mean squared error\n",
    "def get_mse(y_pred, y_true):\n",
    "    mse = mean_squared_error(y_true=y_true, y_pred=y_pred)\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add Neptune experiment observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[neptune] [info   ] Neptune initialized. Open in the app: https://app.neptune.ai/NarcisissticTwitter/Twitter/e/TWIT-22\n",
      "narcissism: 3.333\n",
      "narcissism: 2.111\n",
      "narcissism: 3.556\n",
      "narcissism: 2.111\n",
      "narcissism: 3.222\n",
      "narcissism: 2.444\n",
      "narcissism: 2.222\n",
      "narcissism: 1.111\n",
      "narcissism: 2.111\n",
      "narcissism: 1.222\n",
      "1.5430125\n",
      "[neptune] [info   ] Shutting down background jobs, please wait a moment...\n",
      "[neptune] [info   ] Done!\n",
      "[neptune] [info   ] Waiting for the remaining 1 operations to synchronize with Neptune. Do not kill this process.\n",
      "[neptune] [info   ] All 1 operations synced, thanks for waiting!\n",
      "[neptune] [info   ] Explore the metadata in the Neptune app: https://app.neptune.ai/NarcisissticTwitter/Twitter/e/TWIT-22/metadata\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[neptune] [error  ] Run TWIT-21 received stop signal. Exiting\n",
      "[neptune] [info   ] Shutting down background jobs, please wait a moment...\n",
      "[neptune] [info   ] Done!\n",
      "[neptune] [info   ] All 0 operations synced, thanks for waiting!\n",
      "[neptune] [info   ] Explore the metadata in the Neptune app: https://app.neptune.ai/NarcisissticTwitter/Twitter/e/TWIT-21/metadata\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Run the functions\n",
    "# TODO: Set API token in the environment variable\n",
    "run = neptune.init_run(project = \"NarcisissticTwitter/Twitter\",\n",
    "                       api_token = \"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiJmYmEzZjU5ZS1kZDIzLTQwNTEtYjQ4Ni1hYTlhMTFjY2YzMjIifQ==\")\n",
    "# TODO: Add logging of input posts (and responses?) to Neptune\n",
    "run[\"algorithm\"] = \"Few-shot learning\"\n",
    "params = {\n",
    "    \"model\": model_used,\n",
    "    \"narc_type\": narcism_type,\n",
    "    \"post_type\": post_type,\n",
    "    \"prompt\": model_role,\n",
    "    \"shots\": number_of_shots\n",
    "}\n",
    "run[\"model/parameters\"] = params\n",
    "run.add_tags([\"few-shot\", \"narcissism\", narcism_type])\n",
    "y_pred = []\n",
    "y_true = []\n",
    "for i in range(iterations):\n",
    "    example = get_random_x_posts(train_path, post_type, narcism_type, number_of_shots)\n",
    "    few_shot_prompt = create_few_shot_prompt(example)\n",
    "    input_dic = get_random_x_posts(validate_path, post_type, narcism_type, 1)\n",
    "    input = input_dic.pop(0)\n",
    "    final_prompt = create_final_prompt(few_shot_prompt,model_role)\n",
    "    response = get_response(final_prompt, model, input.get('post'))\n",
    "    y_pred.append(response)\n",
    "    y_true.append(input.get('narcissism'))\n",
    "\n",
    "mse = get_mse(y_pred, y_true)\n",
    "print(mse)\n",
    "run[\"mse\"] = mse\n",
    "run.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "narc-twitter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
