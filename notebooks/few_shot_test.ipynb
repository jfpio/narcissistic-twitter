{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.prompts import FewShotChatMessagePromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "\n",
    "from sklearn.metrics import mean_squared_error \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import neptune\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Why did the loaf of bread end up in therapy?\\n\\nBecause it couldn't rise above its kneady behavior!\""
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\"tell me a short joke about {topic}\")\n",
    "model = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", openai_api_key=os.getenv('OPENAI_API_KEY'))\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "chain = prompt | model | output_parser\n",
    "\n",
    "chain.invoke({\"topic\": \"bread\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_type = 'post_travel' # 'post_travel' or 'post_abortion'\n",
    "narcism_type = 'adm' # 'riv' or 'adm'\n",
    "# model chosen from https://platform.openai.com/docs/models/continuous-model-upgrades\n",
    "model_used = 'gpt-3.5-turbo-0125' # 'gpt-3.5-turbo-0125', 'gpt-4-1106-preview' or 'gpt-4-turbo-2024-04-09'\n",
    "iterations = 10\n",
    "number_of_shots = 5 # somewhere between 3 and 10\n",
    "model_role = \"You are a psychologist and you are assessing a patient's Narcissism. The patient is talking about their recent travel. Return only float number between 1 and 6.\"\n",
    "train_path = \"../data/split/train.csv\"\n",
    "validate_path = \"../data/split/validate.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we used the most basic implementation, there is also option to use Dynamic few-shot prompting, but to my knowledge is not needed is this context as we have only one type of posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'post': 'I wish I could travel 24/7 and get paid for it',\n",
       "  'narcissism': 1.444},\n",
       " {'post': \"Vacations are pricey these days but so worth it! I had the most amazing weekend at ABC resort. Everything about this place screams relaxation and luxury. I'm definitely going back next year. Would you like to come with me?\",\n",
       "  'narcissism': 3.889},\n",
       " {'post': 'I recently visited beautiful Stratford upon Avon as a pit-stop on my way to Minehead, Somerset. I made a point to leave my immediate surroundings and find the birthplace of Shakespeare. I found it interesting but ultimately over-commercialised.',\n",
       "  'narcissism': 3.444},\n",
       " {'post': \"I have just visited Marrakesh.The scenery is like being in Mars.The soil is do red and there's not a person around for miles. Then you will come across a shepherd all alone with his flock. It makes you wonder how he gets food.The transport there is mainly donkey and cart.\",\n",
       "  'narcissism': 3.667},\n",
       " {'post': \"I travel a lot for work, and I get to see all sorts of cool places. I didn't think the American south had as many hidden gems as it did, I think it's a beautiful region with some crazy cool people.\",\n",
       "  'narcissism': 1.222}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get split data using pandas\n",
    "df = pd.read_csv(train_path)\n",
    "\n",
    "# Get the dictionary of the first x posts\n",
    "example = df[[post_type,narcism_type]].iloc[0:number_of_shots]\n",
    "\n",
    "example = example.to_dict(orient='records')\n",
    "\n",
    "# Change the value name\n",
    "for i in range(len(example)):\n",
    "    example[i]['post'] = example[i].pop(post_type)\n",
    "    example[i]['narcissism'] = example[i].pop(narcism_type)\n",
    "\n",
    "example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI(model=model_used, openai_api_key=os.getenv('OPENAI_API_KEY'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a prompt template used to format each example.\n",
    "example_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"human\", \"{post}\"),\n",
    "        (\"ai\", \"result: {narcissism}\"),\n",
    "    ]\n",
    ")\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples=example,\n",
    ")\n",
    "\n",
    "# print(few_shot_prompt.format())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use train and validate dataset!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I travel a lot for work, and I get to see all sorts of cool places. I didn't think the American south had as many hidden gems as it did, I think it's a beautiful region with some crazy cool people.\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = df[[post_type,narcism_type]].iloc[4] # Test on train dataset\n",
    "input = test.iloc[0]\n",
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='Return a narcissism number between 1 and 6.')), FewShotChatMessagePromptTemplate(examples=[{'post': 'I wish I could travel 24/7 and get paid for it', 'narcissism': 1.444}, {'post': \"Vacations are pricey these days but so worth it! I had the most amazing weekend at ABC resort. Everything about this place screams relaxation and luxury. I'm definitely going back next year. Would you like to come with me?\", 'narcissism': 3.889}, {'post': 'I recently visited beautiful Stratford upon Avon as a pit-stop on my way to Minehead, Somerset. I made a point to leave my immediate surroundings and find the birthplace of Shakespeare. I found it interesting but ultimately over-commercialised.', 'narcissism': 3.444}, {'post': \"I have just visited Marrakesh.The scenery is like being in Mars.The soil is do red and there's not a person around for miles. Then you will come across a shepherd all alone with his flock. It makes you wonder how he gets food.The transport there is mainly donkey and cart.\", 'narcissism': 3.667}, {'post': \"I travel a lot for work, and I get to see all sorts of cool places. I didn't think the American south had as many hidden gems as it did, I think it's a beautiful region with some crazy cool people.\", 'narcissism': 1.222}], example_prompt=ChatPromptTemplate(input_variables=['narcissism', 'post'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['post'], template='{post}')), AIMessagePromptTemplate(prompt=PromptTemplate(input_variables=['narcissism'], template='result: {narcissism}'))])), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}'))])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"Return a narcissism number between 1 and 6.\"),\n",
    "        few_shot_prompt,\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "final_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='result: 1.778', response_metadata={'token_usage': {'completion_tokens': 6, 'prompt_tokens': 356, 'total_tokens': 362}, 'model_name': 'gpt-3.5-turbo-1106', 'system_fingerprint': 'fp_592ef5907d', 'finish_reason': 'stop', 'logprobs': None})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = final_prompt | model\n",
    "\n",
    "ai_message = chain.invoke({\"input\": input})\n",
    "\n",
    "ai_message\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.778"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = ai_message.content\n",
    "match = re.search(r'\\d+\\.\\d+', r)\n",
    "if match:\n",
    "    response = float(match.group())\n",
    "else:\n",
    "    response = None\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.222"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "y_true = []\n",
    "y_pred.append(response)\n",
    "y_true.append(test.iloc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3091360000000001"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = mean_squared_error(y_true=y_true, y_pred=y_pred)\n",
    "mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions\n",
    "\n",
    "# get random x posts\n",
    "def get_random_x_posts(path, post_type, narcism_type, number_of_posts):\n",
    "\n",
    "    df = pd.read_csv(path)\n",
    "    example = df[[post_type,narcism_type]].sample(number_of_posts)\n",
    "    example = example.to_dict(orient='records')\n",
    "\n",
    "    # Change the value name\n",
    "    for i in range(len(example)):\n",
    "        example[i]['post'] = example[i].pop(post_type)\n",
    "        example[i]['narcissism'] = example[i].pop(narcism_type)\n",
    "\n",
    "    return example\n",
    "\n",
    "# create a few shot prompt\n",
    "def create_few_shot_prompt(example):\n",
    "    example_prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"human\", \"{post}\"),\n",
    "            (\"ai\", \"narcissism: {narcissism}\"),\n",
    "        ]\n",
    "    )\n",
    "    few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "        example_prompt=example_prompt,\n",
    "        examples=example,\n",
    "    )\n",
    "    return few_shot_prompt\n",
    "\n",
    "# create a final prompt\n",
    "def create_final_prompt(few_shot_prompt,model_role):\n",
    "    final_prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", model_role),\n",
    "            few_shot_prompt,\n",
    "            (\"human\", \"{input}\"),\n",
    "        ]\n",
    "    )\n",
    "    return final_prompt\n",
    "\n",
    "# get float number from a string\n",
    "def get_float(text):\n",
    "    # Use regular expression to find numerical value\n",
    "    match = re.search(r'\\d+\\.\\d+', text)\n",
    "    if match:\n",
    "        float_number = float(match.group())\n",
    "        if float_number is not None:\n",
    "            return float_number\n",
    "        else:\n",
    "            print(f\"Wrong input: {text}\")\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# get the response\n",
    "def get_response(final_prompt, model, input):\n",
    "    chain = final_prompt | model\n",
    "    ai_message = chain.invoke({\"input\": input})\n",
    "    response = ai_message.content\n",
    "    return response\n",
    "\n",
    "# get the mean squared error\n",
    "def get_mse(y_pred, y_true):\n",
    "    mse = mean_squared_error(y_true=y_true, y_pred=y_pred)\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add Neptune experiment observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[neptune] [info   ] Neptune initialized. Open in the app: https://app.neptune.ai/NarcisissticTwitter/Twitter/e/TWIT-39\n",
      "1.2651375531914892\n",
      "[neptune] [info   ] Shutting down background jobs, please wait a moment...\n",
      "[neptune] [info   ] Done!\n",
      "[neptune] [info   ] Waiting for the remaining 1 operations to synchronize with Neptune. Do not kill this process.\n",
      "[neptune] [info   ] All 1 operations synced, thanks for waiting!\n",
      "[neptune] [info   ] Explore the metadata in the Neptune app: https://app.neptune.ai/NarcisissticTwitter/Twitter/e/TWIT-39/metadata\n"
     ]
    }
   ],
   "source": [
    "# Run the functions\n",
    "run = neptune.init_run(project = os.getenv('NEPTUNE_PROJECT'),\n",
    "                       api_token = os.getenv('NEPTUNE_API_TOKEN'),\n",
    "                       source_files=[\"few_shot_test.ipynb\"],\n",
    "                       tags=[\"few-shot\", narcism_type, post_type])\n",
    "\n",
    "run[\"type\"] = \"Few-shot learning\"\n",
    "params = {\n",
    "    \"model\": model_used,\n",
    "    \"narc_type\": narcism_type,\n",
    "    \"post_type\": post_type,\n",
    "    \"prompt\": model_role,\n",
    "    \"shots\": number_of_shots\n",
    "}\n",
    "run[\"model/parameters\"] = params # Save the parameters\n",
    "\n",
    "y_pred = []\n",
    "y_true = []\n",
    "\n",
    "test_df = pd.read_csv(validate_path)\n",
    "testset = test_df[[post_type,narcism_type]]\n",
    "\n",
    "problems = []\n",
    "\n",
    "for i in range(test.shape[0]):\n",
    "    example = get_random_x_posts(train_path, post_type, narcism_type, number_of_shots) # Get some random examples\n",
    "    few_shot_prompt = create_few_shot_prompt(example) \n",
    "    #input_dic = get_random_x_posts(validate_path, post_type, narcism_type, 1)\n",
    "    #input = input_dic.pop(0)\n",
    "    input = testset.iloc[i]\n",
    "    final_prompt = create_final_prompt(few_shot_prompt,model_role)\n",
    "    response_str = get_response(final_prompt, model, input.get(post_type))\n",
    "    response = get_float(response_str)\n",
    "\n",
    "    if response is not None: # Check if the model returned a number\n",
    "        y_pred.append(response)\n",
    "        y_true.append(input.get(narcism_type))\n",
    "    else: # Else save the prompt that caused the error\n",
    "        row_to_add = {'post': input.get(post_type), 'post_type': post_type, 'model_role': model_role, 'date': pd.Timestamp.now()}\n",
    "        problems.append(row_to_add)\n",
    "\n",
    "\n",
    "mse = get_mse(y_pred, y_true) # Calculate the mean squared error\n",
    "print(mse) \n",
    "run[\"mse\"] = mse\n",
    "run.stop() # Stop the run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a dataframe of the problems\n",
    "problems_df = pd.DataFrame(problems)\n",
    "problems_df.to_csv(\"../data/responses/few_shot.csv\", mode='a', index=False, header=False)\n",
    "\n",
    "problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "narc-twitter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
