{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.prompts import FewShotChatMessagePromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "\n",
    "from sklearn.metrics import mean_squared_error \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import neptune\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Why was the bread always so calm? \\nBecause it kneaded to relax!'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\"tell me a short joke about {topic}\")\n",
    "model = ChatOpenAI(model=\"gpt-3.5-turbo-1106\", openai_api_key=os.getenv('OPENAI_API_KEY'))\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "chain = prompt | model | output_parser\n",
    "\n",
    "chain.invoke({\"topic\": \"bread\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_type = 'post_travel'\n",
    "narcism_type = 'adm'\n",
    "model_used = \"gpt-3.5-turbo-1106\"\n",
    "iterations = 10\n",
    "number_of_shots = 5 # somewhere between 3 and 10\n",
    "model_role = \"You are a psychologist and you are assessing a patient's Narcissism. The patient is talking about their recent travel. Return only float number between 1 and 6.\"\n",
    "train_path = \"../data/split/train.csv\"\n",
    "validate_path = \"../data/split/validate.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we used the most basic implementation, there is also option to use Dynamic few-shot prompting, but to my knowledge is not needed is this context as we have only one type of posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'post': 'I wish I could travel 24/7 and get paid for it',\n",
       "  'narcissism': 1.444},\n",
       " {'post': \"Vacations are pricey these days but so worth it! I had the most amazing weekend at ABC resort. Everything about this place screams relaxation and luxury. I'm definitely going back next year. Would you like to come with me?\",\n",
       "  'narcissism': 3.889},\n",
       " {'post': 'I recently visited beautiful Stratford upon Avon as a pit-stop on my way to Minehead, Somerset. I made a point to leave my immediate surroundings and find the birthplace of Shakespeare. I found it interesting but ultimately over-commercialised.',\n",
       "  'narcissism': 3.444},\n",
       " {'post': \"I have just visited Marrakesh.The scenery is like being in Mars.The soil is do red and there's not a person around for miles. Then you will come across a shepherd all alone with his flock. It makes you wonder how he gets food.The transport there is mainly donkey and cart.\",\n",
       "  'narcissism': 3.667},\n",
       " {'post': \"I travel a lot for work, and I get to see all sorts of cool places. I didn't think the American south had as many hidden gems as it did, I think it's a beautiful region with some crazy cool people.\",\n",
       "  'narcissism': 1.222}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get split data using pandas\n",
    "df = pd.read_csv(train_path)\n",
    "\n",
    "# Get the dictionary of the first x posts\n",
    "example = df[[post_type,narcism_type]].iloc[0:number_of_shots]\n",
    "\n",
    "example = example.to_dict(orient='records')\n",
    "\n",
    "# Change the value name\n",
    "for i in range(len(example)):\n",
    "    example[i]['post'] = example[i].pop(post_type)\n",
    "    example[i]['narcissism'] = example[i].pop(narcism_type)\n",
    "\n",
    "example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI(model=model_used, openai_api_key=os.getenv('OPENAI_API_KEY'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a prompt template used to format each example.\n",
    "example_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"human\", \"{post}\"),\n",
    "        (\"ai\", \"result: {narcissism}\"),\n",
    "    ]\n",
    ")\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples=example,\n",
    ")\n",
    "\n",
    "# print(few_shot_prompt.format())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use train and validate dataset!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I travel a lot for work, and I get to see all sorts of cool places. I didn't think the American south had as many hidden gems as it did, I think it's a beautiful region with some crazy cool people.\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = df[[post_type,narcism_type]].iloc[4]\n",
    "input = test.iloc[0]\n",
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='Return a narcissism number between 1 and 6.')), FewShotChatMessagePromptTemplate(examples=[{'post': 'I wish I could travel 24/7 and get paid for it', 'narcissism': 1.444}, {'post': \"Vacations are pricey these days but so worth it! I had the most amazing weekend at ABC resort. Everything about this place screams relaxation and luxury. I'm definitely going back next year. Would you like to come with me?\", 'narcissism': 3.889}, {'post': 'I recently visited beautiful Stratford upon Avon as a pit-stop on my way to Minehead, Somerset. I made a point to leave my immediate surroundings and find the birthplace of Shakespeare. I found it interesting but ultimately over-commercialised.', 'narcissism': 3.444}, {'post': \"I have just visited Marrakesh.The scenery is like being in Mars.The soil is do red and there's not a person around for miles. Then you will come across a shepherd all alone with his flock. It makes you wonder how he gets food.The transport there is mainly donkey and cart.\", 'narcissism': 3.667}, {'post': \"I travel a lot for work, and I get to see all sorts of cool places. I didn't think the American south had as many hidden gems as it did, I think it's a beautiful region with some crazy cool people.\", 'narcissism': 1.222}], example_prompt=ChatPromptTemplate(input_variables=['narcissism', 'post'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['post'], template='{post}')), AIMessagePromptTemplate(prompt=PromptTemplate(input_variables=['narcissism'], template='result: {narcissism}'))])), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}'))])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"Return a narcissism number between 1 and 6.\"),\n",
    "        few_shot_prompt,\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "final_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='result: 1.556', response_metadata={'token_usage': {'completion_tokens': 6, 'prompt_tokens': 356, 'total_tokens': 362}, 'model_name': 'gpt-3.5-turbo-1106', 'system_fingerprint': 'fp_89448ee5dc', 'finish_reason': 'stop', 'logprobs': None})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = final_prompt | model\n",
    "\n",
    "ai_message = chain.invoke({\"input\": input})\n",
    "\n",
    "ai_message\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.556"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = ai_message.content\n",
    "match = re.search(r'\\d+\\.\\d+', r)\n",
    "if match:\n",
    "    response = float(match.group())\n",
    "else:\n",
    "    response = None\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.222"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "y_true = []\n",
    "y_pred.append(response)\n",
    "y_true.append(test.iloc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11155600000000004"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = mean_squared_error(y_true=y_true, y_pred=y_pred)\n",
    "mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions\n",
    "\n",
    "# get random x posts\n",
    "def get_random_x_posts(path, post_type, narcism_type, number_of_posts):\n",
    "\n",
    "    df = pd.read_csv(path)\n",
    "    example = df[[post_type,narcism_type]].sample(number_of_posts)\n",
    "    example = example.to_dict(orient='records')\n",
    "\n",
    "    # Change the value name\n",
    "    for i in range(len(example)):\n",
    "        example[i]['post'] = example[i].pop(post_type)\n",
    "        example[i]['narcissism'] = example[i].pop(narcism_type)\n",
    "\n",
    "    return example\n",
    "\n",
    "# create a few shot prompt\n",
    "def create_few_shot_prompt(example):\n",
    "    example_prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"human\", \"{post}\"),\n",
    "            (\"ai\", \"narcissism: {narcissism}\"),\n",
    "        ]\n",
    "    )\n",
    "    few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "        example_prompt=example_prompt,\n",
    "        examples=example,\n",
    "    )\n",
    "    return few_shot_prompt\n",
    "\n",
    "# create a final prompt\n",
    "def create_final_prompt(few_shot_prompt,model_role):\n",
    "    final_prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", model_role),\n",
    "            few_shot_prompt,\n",
    "            (\"human\", \"{input}\"),\n",
    "        ]\n",
    "    )\n",
    "    return final_prompt\n",
    "\n",
    "# get float number from a string\n",
    "def get_float(text):\n",
    "    # Use regular expression to find numerical value\n",
    "    match = re.search(r'\\d+\\.\\d+', text)\n",
    "    if match:\n",
    "        float_number = float(match.group())\n",
    "        if float_number is not None:\n",
    "            return float_number\n",
    "        else:\n",
    "            print(f\"Wrong input: {text}\")\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# get the response\n",
    "def get_response(final_prompt, model, input):\n",
    "    chain = final_prompt | model\n",
    "    ai_message = chain.invoke({\"input\": input})\n",
    "    response = ai_message.content\n",
    "    print(response)\n",
    "    # get a float number from a string\n",
    "    response = get_float(response)\n",
    "    return response\n",
    "\n",
    "# get the mean squared error\n",
    "def get_mse(y_pred, y_true):\n",
    "    mse = mean_squared_error(y_true=y_true, y_pred=y_pred)\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add Neptune experiment observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[neptune] [warning] NeptuneWarning: The following monitoring options are disabled by default in interactive sessions: 'capture_stdout', 'capture_stderr', 'capture_traceback', and 'capture_hardware_metrics'. To enable them, set each parameter to 'True' when initializing the run. The monitoring will continue until you call run.stop() or the kernel stops. Also note: Your source files can only be tracked if you pass the path(s) to the 'source_code' argument. For help, see the Neptune docs: https://docs.neptune.ai/logging/source_code/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[neptune] [info   ] Neptune initialized. Open in the app: https://app.neptune.ai/NarcisissticTwitter/Twitter/e/TWIT-29\n",
      "narcissism: 3.556\n",
      "narcissism: 2.111\n",
      "narcissism: 3.111\n",
      "narcissism: 5.0\n",
      "narcissism: 1.444\n",
      "narcissism: 1.111\n",
      "narcissism: 3.111\n",
      "narcissism: 3.667\n",
      "narcissism: 1.111\n",
      "narcissism: 3.222\n",
      "2.1385507999999995\n",
      "[neptune] [info   ] Shutting down background jobs, please wait a moment...\n",
      "[neptune] [info   ] Done!\n",
      "[neptune] [info   ] Waiting for the remaining 1 operations to synchronize with Neptune. Do not kill this process.\n",
      "[neptune] [info   ] All 1 operations synced, thanks for waiting!\n",
      "[neptune] [info   ] Explore the metadata in the Neptune app: https://app.neptune.ai/NarcisissticTwitter/Twitter/e/TWIT-29/metadata\n"
     ]
    }
   ],
   "source": [
    "# Run the functions\n",
    "run = neptune.init_run(project = os.getenv('NEPTUNE_PROJECT'),\n",
    "                       api_token = os.getenv('NEPTUNE_API_TOKEN'),\n",
    "                       source_files=[\"few_shot_test.ipynb\"],\n",
    "                       tags=[\"few-shot\", \"narcissism\", narcism_type])\n",
    "# TODO: Add logging of input posts (and responses?) to Neptune\n",
    "run[\"type\"] = \"Few-shot learning\"\n",
    "params = {\n",
    "    \"model\": model_used,\n",
    "    \"narc_type\": narcism_type,\n",
    "    \"post_type\": post_type,\n",
    "    \"prompt\": model_role,\n",
    "    \"shots\": number_of_shots\n",
    "}\n",
    "run[\"model/parameters\"] = params\n",
    "y_pred = []\n",
    "y_true = []\n",
    "for i in range(iterations):\n",
    "    example = get_random_x_posts(train_path, post_type, narcism_type, number_of_shots)\n",
    "    few_shot_prompt = create_few_shot_prompt(example)\n",
    "    input_dic = get_random_x_posts(validate_path, post_type, narcism_type, 1)\n",
    "    input = input_dic.pop(0)\n",
    "    final_prompt = create_final_prompt(few_shot_prompt,model_role)\n",
    "    response = get_response(final_prompt, model, input.get('post'))\n",
    "    y_pred.append(response)\n",
    "    y_true.append(input.get('narcissism'))\n",
    "\n",
    "mse = get_mse(y_pred, y_true)\n",
    "print(mse)\n",
    "run[\"mse\"] = mse\n",
    "run.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "narc-twitter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
