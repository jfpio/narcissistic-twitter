{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import pipeline\n",
    "\n",
    "# TqdmWarning: IProgress not found.\n",
    "\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import TFAutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer\n",
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "import csv\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "task='irony'\n",
    "MODEL = f\"cardiffnlp/twitter-roberta-base-{task}\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=[]\n",
    "mapping_link = f\"https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/{task}/mapping.txt\"\n",
    "with urllib.request.urlopen(mapping_link) as f:\n",
    "    html = f.read().decode('utf-8').split(\"\\n\")\n",
    "    csvreader = csv.reader(html, delimiter='\\t')\n",
    "labels = [row[1] for row in csvreader if len(row) > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
    "model.save_pretrained(MODEL)\n",
    "\n",
    "text = \"Great, it broke the first day...\"\n",
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "output = model(**encoded_input)\n",
    "scores = output[0][0].detach().numpy()\n",
    "scores = softmax(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranking = np.argsort(scores)\n",
    "ranking = ranking[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, tokenizer, text):\n",
    "    encoded_input = tokenizer(text, return_tensors='pt')\n",
    "    output = model(**encoded_input)\n",
    "    scores = output[0][0].detach().numpy()\n",
    "    scores = softmax(scores)\n",
    "    ranking = np.argsort(scores)\n",
    "    ranking = ranking[::-1]\n",
    "    scores_array = []\n",
    "    for i in range(scores.shape[0]):\n",
    "        scores_dict = {}\n",
    "        l = labels[ranking[i]]\n",
    "        scores_dict['label'] = l\n",
    "        s = scores[ranking[i]]\n",
    "        scores_dict['score'] = s\n",
    "        scores_array.append(scores_dict)\n",
    "    return scores_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_travel</th>\n",
       "      <th>post_abortion</th>\n",
       "      <th>adm</th>\n",
       "      <th>riv</th>\n",
       "      <th>gender</th>\n",
       "      <th>gender_3_text</th>\n",
       "      <th>age</th>\n",
       "      <th>ethnic_background</th>\n",
       "      <th>ethnic_background_8_text</th>\n",
       "      <th>education</th>\n",
       "      <th>...</th>\n",
       "      <th>instagram</th>\n",
       "      <th>tiktok</th>\n",
       "      <th>linkedin</th>\n",
       "      <th>pinterest</th>\n",
       "      <th>other</th>\n",
       "      <th>other_portals_7_text</th>\n",
       "      <th>post_ai</th>\n",
       "      <th>tr_emotion</th>\n",
       "      <th>ab_emotion</th>\n",
       "      <th>ai_emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>went on a sick trip somewhere really fun and c...</td>\n",
       "      <td>anyone know where to buy new hangers?</td>\n",
       "      <td>1.222</td>\n",
       "      <td>1.667</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ai is weird. i want it to do menial tasks not ...</td>\n",
       "      <td>[[{'label': 'joy', 'score': 0.950767457485199}...</td>\n",
       "      <td>[[{'label': 'neutral', 'score': 0.701108157634...</td>\n",
       "      <td>[[{'label': 'disgust', 'score': 0.564288496971...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I went to the beach this weekend and had a gre...</td>\n",
       "      <td>Banning abortion is telling someone else what ...</td>\n",
       "      <td>5.778</td>\n",
       "      <td>1.222</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OpenAI will contribute many great things to ou...</td>\n",
       "      <td>[[{'label': 'joy', 'score': 0.99103844165802},...</td>\n",
       "      <td>[[{'label': 'disgust', 'score': 0.591954231262...</td>\n",
       "      <td>[[{'label': 'neutral', 'score': 0.799880325794...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I had a beautiful time in Croatia with my fami...</td>\n",
       "      <td>I'm deeply disappointed to learn that the gove...</td>\n",
       "      <td>4.333</td>\n",
       "      <td>1.889</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I've found AI to be super helpful in my recent...</td>\n",
       "      <td>[[{'label': 'joy', 'score': 0.9921907782554626...</td>\n",
       "      <td>[[{'label': 'sadness', 'score': 0.884934008121...</td>\n",
       "      <td>[[{'label': 'joy', 'score': 0.6637662649154663...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>On vacation - this place is amazing! I definit...</td>\n",
       "      <td>I’m devastated that this has happened - women ...</td>\n",
       "      <td>2.444</td>\n",
       "      <td>2.222</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Used an AI service to make some cute and funny...</td>\n",
       "      <td>[[{'label': 'joy', 'score': 0.7306950092315674...</td>\n",
       "      <td>[[{'label': 'sadness', 'score': 0.951866924762...</td>\n",
       "      <td>[[{'label': 'joy', 'score': 0.5088626146316528...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Last week I had the pleasure of traveling up a...</td>\n",
       "      <td>It is unconstitutional to deny a woman's right...</td>\n",
       "      <td>2.889</td>\n",
       "      <td>2.222</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AI should be closely monitored and ensured tha...</td>\n",
       "      <td>[[{'label': 'joy', 'score': 0.9787710309028625...</td>\n",
       "      <td>[[{'label': 'anger', 'score': 0.47481924295425...</td>\n",
       "      <td>[[{'label': 'neutral', 'score': 0.853263556957...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         post_travel  \\\n",
       "0  went on a sick trip somewhere really fun and c...   \n",
       "1  I went to the beach this weekend and had a gre...   \n",
       "2  I had a beautiful time in Croatia with my fami...   \n",
       "3  On vacation - this place is amazing! I definit...   \n",
       "4  Last week I had the pleasure of traveling up a...   \n",
       "\n",
       "                                       post_abortion    adm    riv  gender  \\\n",
       "0              anyone know where to buy new hangers?  1.222  1.667     2.0   \n",
       "1  Banning abortion is telling someone else what ...  5.778  1.222     1.0   \n",
       "2  I'm deeply disappointed to learn that the gove...  4.333  1.889     2.0   \n",
       "3  I’m devastated that this has happened - women ...  2.444  2.222     2.0   \n",
       "4  It is unconstitutional to deny a woman's right...  2.889  2.222     2.0   \n",
       "\n",
       "  gender_3_text  age  ethnic_background ethnic_background_8_text  education  \\\n",
       "0           NaN   38                1.0                      NaN        4.0   \n",
       "1           NaN   45                1.0                      NaN        2.0   \n",
       "2           NaN   34                5.0                      NaN        1.0   \n",
       "3           NaN   41                1.0                      NaN        2.0   \n",
       "4           NaN   36                4.0                      NaN        2.0   \n",
       "\n",
       "   ... instagram  tiktok linkedin  pinterest  other  other_portals_7_text  \\\n",
       "0  ...       1.0     1.0      NaN        NaN    NaN                   NaN   \n",
       "1  ...       1.0     1.0      1.0        NaN    NaN                   NaN   \n",
       "2  ...       1.0     NaN      1.0        NaN    NaN                   NaN   \n",
       "3  ...       1.0     NaN      1.0        1.0    NaN                   NaN   \n",
       "4  ...       NaN     NaN      1.0        1.0    NaN                   NaN   \n",
       "\n",
       "                                             post_ai  \\\n",
       "0  ai is weird. i want it to do menial tasks not ...   \n",
       "1  OpenAI will contribute many great things to ou...   \n",
       "2  I've found AI to be super helpful in my recent...   \n",
       "3  Used an AI service to make some cute and funny...   \n",
       "4  AI should be closely monitored and ensured tha...   \n",
       "\n",
       "                                          tr_emotion  \\\n",
       "0  [[{'label': 'joy', 'score': 0.950767457485199}...   \n",
       "1  [[{'label': 'joy', 'score': 0.99103844165802},...   \n",
       "2  [[{'label': 'joy', 'score': 0.9921907782554626...   \n",
       "3  [[{'label': 'joy', 'score': 0.7306950092315674...   \n",
       "4  [[{'label': 'joy', 'score': 0.9787710309028625...   \n",
       "\n",
       "                                          ab_emotion  \\\n",
       "0  [[{'label': 'neutral', 'score': 0.701108157634...   \n",
       "1  [[{'label': 'disgust', 'score': 0.591954231262...   \n",
       "2  [[{'label': 'sadness', 'score': 0.884934008121...   \n",
       "3  [[{'label': 'sadness', 'score': 0.951866924762...   \n",
       "4  [[{'label': 'anger', 'score': 0.47481924295425...   \n",
       "\n",
       "                                          ai_emotion  \n",
       "0  [[{'label': 'disgust', 'score': 0.564288496971...  \n",
       "1  [[{'label': 'neutral', 'score': 0.799880325794...  \n",
       "2  [[{'label': 'joy', 'score': 0.6637662649154663...  \n",
       "3  [[{'label': 'joy', 'score': 0.5088626146316528...  \n",
       "4  [[{'label': 'neutral', 'score': 0.853263556957...  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data_path\n",
    "data_path = \"../data/reporting/emotion_data.csv\"\n",
    "\n",
    "# read data\n",
    "data = pd.read_csv(data_path)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = data[\"post_abortion\"][2]\n",
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "output = model(**encoded_input)\n",
    "scores = output[0][0].detach().numpy()\n",
    "scores = softmax(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add new column to data\n",
    "data[\"tr_irony\"] = data[\"post_travel\"].apply(lambda x: predict(model, tokenizer, x))\n",
    "data[\"ab_irony\"] = data[\"post_abortion\"].apply(lambda x: predict(model, tokenizer, x))\n",
    "data[\"ai_irony\"] = data[\"post_ai\"].apply(lambda x: predict(model, tokenizer, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data into reporting folder\n",
    "data.to_csv(\"../data/reporting/em_ir_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_column_narc_count(data, narc_type, column_type, low = True, n = 100):\n",
    "    temp_data = data.sort_values(narc_type, ascending=low).head(n)\n",
    "    min = temp_data[narc_type].min()\n",
    "    max = temp_data[narc_type].max()\n",
    "    temp_data = temp_data[[column_type]]\n",
    "    emotion_count = {}\n",
    "    for i in range(n):\n",
    "        label  = temp_data.iloc[i,0][0]['label']\n",
    "        if label in emotion_count:\n",
    "            emotion_count[label] += 1\n",
    "        else:\n",
    "            emotion_count[label] = 1\n",
    "    #sort emotion count\n",
    "    emotion_count = dict(sorted(emotion_count.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "    return emotion_count, min, max\n",
    "\n",
    "def print_column_narc_count(data, narc_type, column_type, n = 100):\n",
    "    emotion_count, min, max = get_column_narc_count(data, narc_type, column_type,low = False, n = n)\n",
    "    print(f\"Emotion count for {n} highest {narc_type} {column_type} posts\")\n",
    "    print(f\"Min {narc_type}: {min}\")\n",
    "    print(f\"Max {narc_type}: {max}\")\n",
    "    print(emotion_count)\n",
    "    emotion_count, min, max = get_column_narc_count(data, narc_type, column_type,low = True, n = n)\n",
    "    print(\"\\n\")\n",
    "    print(f\"Emotion count for {n} lowest {narc_type} {column_type} posts\")\n",
    "    print(f\"Min {narc_type}: {min}\")\n",
    "    print(f\"Max {narc_type}: {max}\")\n",
    "    print(emotion_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emotion count for 100 highest adm tr_irony posts\n",
      "Min adm: 4.0\n",
      "Max adm: 5.889\n",
      "{'non_irony': 86, 'irony': 14}\n",
      "\n",
      "\n",
      "Emotion count for 100 lowest adm tr_irony posts\n",
      "Min adm: 1.111\n",
      "Max adm: 2.556\n",
      "{'non_irony': 93, 'irony': 7}\n"
     ]
    }
   ],
   "source": [
    "print_column_narc_count(data,'adm','tr_irony', n = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emotion count for 100 highest adm ab_irony posts\n",
      "Min adm: 4.0\n",
      "Max adm: 5.889\n",
      "{'non_irony': 69, 'irony': 31}\n",
      "\n",
      "\n",
      "Emotion count for 100 lowest adm ab_irony posts\n",
      "Min adm: 1.111\n",
      "Max adm: 2.556\n",
      "{'non_irony': 70, 'irony': 30}\n",
      "\n",
      "\n",
      "Emotion count for 100 highest adm ai_irony posts\n",
      "Min adm: 4.0\n",
      "Max adm: 5.889\n",
      "{'non_irony': 58, 'irony': 42}\n",
      "\n",
      "\n",
      "Emotion count for 100 lowest adm ai_irony posts\n",
      "Min adm: 1.111\n",
      "Max adm: 2.556\n",
      "{'non_irony': 61, 'irony': 39}\n"
     ]
    }
   ],
   "source": [
    "print_column_narc_count(data,'adm','ab_irony', n = 100)\n",
    "print(\"\\n\")\n",
    "print_column_narc_count(data,'adm','ai_irony', n = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emotion count for 100 highest riv tr_irony posts\n",
      "Min riv: 2.333\n",
      "Max riv: 5.111\n",
      "{'non_irony': 86, 'irony': 14}\n",
      "\n",
      "\n",
      "Emotion count for 100 lowest riv tr_irony posts\n",
      "Min riv: 1.0\n",
      "Max riv: 1.556\n",
      "{'non_irony': 93, 'irony': 7}\n"
     ]
    }
   ],
   "source": [
    "print_column_narc_count(data,'riv','tr_irony', n = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emotion count for 100 highest riv ab_irony posts\n",
      "Min riv: 2.333\n",
      "Max riv: 5.111\n",
      "{'non_irony': 70, 'irony': 30}\n",
      "\n",
      "\n",
      "Emotion count for 100 lowest riv ab_irony posts\n",
      "Min riv: 1.0\n",
      "Max riv: 1.556\n",
      "{'non_irony': 76, 'irony': 24}\n",
      "\n",
      "\n",
      "Emotion count for 100 highest riv ai_irony posts\n",
      "Min riv: 2.333\n",
      "Max riv: 5.111\n",
      "{'non_irony': 61, 'irony': 39}\n",
      "\n",
      "\n",
      "Emotion count for 100 lowest riv ai_irony posts\n",
      "Min riv: 1.0\n",
      "Max riv: 1.556\n",
      "{'non_irony': 59, 'irony': 41}\n"
     ]
    }
   ],
   "source": [
    "print_column_narc_count(data,'riv','ab_irony', n = 100)\n",
    "print(\"\\n\")\n",
    "print_column_narc_count(data,'riv','ai_irony', n = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "task='hate'\n",
    "MODEL = f\"cardiffnlp/twitter-roberta-base-{task}-latest\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=[]\n",
    "mapping_link = f\"https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/{task}/mapping.txt\"\n",
    "with urllib.request.urlopen(mapping_link) as f:\n",
    "    html = f.read().decode('utf-8').split(\"\\n\")\n",
    "    csvreader = csv.reader(html, delimiter='\\t')\n",
    "labels = [row[1] for row in csvreader if len(row) > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
    "model.save_pretrained(MODEL)\n",
    "\n",
    "text = \"Great, it broke the first day...\"\n",
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "output = model(**encoded_input)\n",
    "scores = output[0][0].detach().numpy()\n",
    "scores = softmax(scores)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"tr_hate\"] = data[\"post_travel\"].apply(lambda x: predict(model, tokenizer, x))\n",
    "data[\"ab_hate\"] = data[\"post_abortion\"].apply(lambda x: predict(model, tokenizer, x))\n",
    "data[\"ai_hate\"] = data[\"post_ai\"].apply(lambda x: predict(model, tokenizer, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data into reporting folder\n",
    "data.to_csv(\"../data/reporting/em_ir_ht_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emotion count for 100 highest adm tr_hate posts\n",
      "Min adm: 4.0\n",
      "Max adm: 5.889\n",
      "{'not-hate': 100}\n",
      "\n",
      "\n",
      "Emotion count for 100 lowest adm tr_hate posts\n",
      "Min adm: 1.111\n",
      "Max adm: 2.556\n",
      "{'not-hate': 100}\n",
      "\n",
      "\n",
      "Emotion count for 100 highest adm ab_hate posts\n",
      "Min adm: 4.0\n",
      "Max adm: 5.889\n",
      "{'not-hate': 99, 'hate': 1}\n",
      "\n",
      "\n",
      "Emotion count for 100 lowest adm ab_hate posts\n",
      "Min adm: 1.111\n",
      "Max adm: 2.556\n",
      "{'not-hate': 98, 'hate': 2}\n",
      "\n",
      "\n",
      "Emotion count for 100 highest adm ai_hate posts\n",
      "Min adm: 4.0\n",
      "Max adm: 5.889\n",
      "{'not-hate': 100}\n",
      "\n",
      "\n",
      "Emotion count for 100 lowest adm ai_hate posts\n",
      "Min adm: 1.111\n",
      "Max adm: 2.556\n",
      "{'not-hate': 100}\n"
     ]
    }
   ],
   "source": [
    "print_column_narc_count(data,'adm','tr_hate', n = 100)\n",
    "print(\"\\n\")\n",
    "print_column_narc_count(data,'adm','ab_hate', n = 100)\n",
    "print(\"\\n\")\n",
    "print_column_narc_count(data,'adm','ai_hate', n = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emotion count for 100 highest riv tr_hate posts\n",
      "Min riv: 2.333\n",
      "Max riv: 5.111\n",
      "{'not-hate': 100}\n",
      "\n",
      "\n",
      "Emotion count for 100 lowest riv tr_hate posts\n",
      "Min riv: 1.0\n",
      "Max riv: 1.556\n",
      "{'not-hate': 100}\n",
      "\n",
      "\n",
      "Emotion count for 100 highest riv ab_hate posts\n",
      "Min riv: 2.333\n",
      "Max riv: 5.111\n",
      "{'not-hate': 97, 'hate': 3}\n",
      "\n",
      "\n",
      "Emotion count for 100 lowest riv ab_hate posts\n",
      "Min riv: 1.0\n",
      "Max riv: 1.556\n",
      "{'not-hate': 99, 'hate': 1}\n",
      "\n",
      "\n",
      "Emotion count for 100 highest riv ai_hate posts\n",
      "Min riv: 2.333\n",
      "Max riv: 5.111\n",
      "{'not-hate': 100}\n",
      "\n",
      "\n",
      "Emotion count for 100 lowest riv ai_hate posts\n",
      "Min riv: 1.0\n",
      "Max riv: 1.556\n",
      "{'not-hate': 100}\n"
     ]
    }
   ],
   "source": [
    "print_column_narc_count(data,'riv','tr_hate', n = 100)\n",
    "print(\"\\n\")\n",
    "print_column_narc_count(data,'riv','ab_hate', n = 100)\n",
    "print(\"\\n\")\n",
    "print_column_narc_count(data,'riv','ai_hate', n = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Offensive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "task='offensive'\n",
    "MODEL = f\"cardiffnlp/twitter-roberta-base-{task}\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=[]\n",
    "mapping_link = f\"https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/{task}/mapping.txt\"\n",
    "with urllib.request.urlopen(mapping_link) as f:\n",
    "    html = f.read().decode('utf-8').split(\"\\n\")\n",
    "    csvreader = csv.reader(html, delimiter='\\t')\n",
    "labels = [row[1] for row in csvreader if len(row) > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.82735324, 0.17264678], dtype=float32)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
    "model.save_pretrained(MODEL)\n",
    "\n",
    "text = \"Good night\"\n",
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "output = model(**encoded_input)\n",
    "scores = output[0][0].detach().numpy()\n",
    "scores = softmax(scores)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'not-offensive', 'score': 0.6869133},\n",
       " {'label': 'offensive', 'score': 0.31308672}]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(model, tokenizer, data[\"post_travel\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"tr_hate\"] = data[\"post_travel\"].apply(lambda x: predict(model, tokenizer, x))\n",
    "data[\"ab_hate\"] = data[\"post_abortion\"].apply(lambda x: predict(model, tokenizer, x))\n",
    "data[\"ai_hate\"] = data[\"post_ai\"].apply(lambda x: predict(model, tokenizer, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data into reporting folder\n",
    "data.to_csv(\"../data/reporting/four_classes_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emotion count for 100 highest adm tr_hate posts\n",
      "Min adm: 4.0\n",
      "Max adm: 5.889\n",
      "{'not-offensive': 100}\n",
      "\n",
      "\n",
      "Emotion count for 100 lowest adm tr_hate posts\n",
      "Min adm: 1.111\n",
      "Max adm: 2.556\n",
      "{'not-offensive': 99, 'offensive': 1}\n",
      "\n",
      "\n",
      "Emotion count for 100 highest adm ab_hate posts\n",
      "Min adm: 4.0\n",
      "Max adm: 5.889\n",
      "{'not-offensive': 84, 'offensive': 16}\n",
      "\n",
      "\n",
      "Emotion count for 100 lowest adm ab_hate posts\n",
      "Min adm: 1.111\n",
      "Max adm: 2.556\n",
      "{'not-offensive': 64, 'offensive': 36}\n",
      "\n",
      "\n",
      "Emotion count for 100 highest adm ai_hate posts\n",
      "Min adm: 4.0\n",
      "Max adm: 5.889\n",
      "{'not-offensive': 98, 'offensive': 2}\n",
      "\n",
      "\n",
      "Emotion count for 100 lowest adm ai_hate posts\n",
      "Min adm: 1.111\n",
      "Max adm: 2.556\n",
      "{'not-offensive': 98, 'offensive': 2}\n"
     ]
    }
   ],
   "source": [
    "print_column_narc_count(data,'adm','tr_hate', n = 100)\n",
    "print(\"\\n\")\n",
    "print_column_narc_count(data,'adm','ab_hate', n = 100)\n",
    "print(\"\\n\")\n",
    "print_column_narc_count(data,'adm','ai_hate', n = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emotion count for 100 highest riv tr_hate posts\n",
      "Min riv: 2.333\n",
      "Max riv: 5.111\n",
      "{'not-offensive': 100}\n",
      "\n",
      "\n",
      "Emotion count for 100 lowest riv tr_hate posts\n",
      "Min riv: 1.0\n",
      "Max riv: 1.556\n",
      "{'not-offensive': 100}\n",
      "\n",
      "\n",
      "Emotion count for 100 highest riv ab_hate posts\n",
      "Min riv: 2.333\n",
      "Max riv: 5.111\n",
      "{'not-offensive': 78, 'offensive': 22}\n",
      "\n",
      "\n",
      "Emotion count for 100 lowest riv ab_hate posts\n",
      "Min riv: 1.0\n",
      "Max riv: 1.556\n",
      "{'not-offensive': 78, 'offensive': 22}\n",
      "\n",
      "\n",
      "Emotion count for 100 highest riv ai_hate posts\n",
      "Min riv: 2.333\n",
      "Max riv: 5.111\n",
      "{'not-offensive': 96, 'offensive': 4}\n",
      "\n",
      "\n",
      "Emotion count for 100 lowest riv ai_hate posts\n",
      "Min riv: 1.0\n",
      "Max riv: 1.556\n",
      "{'not-offensive': 96, 'offensive': 4}\n"
     ]
    }
   ],
   "source": [
    "print_column_narc_count(data,'riv','tr_hate', n = 100)\n",
    "print(\"\\n\")\n",
    "print_column_narc_count(data,'riv','ab_hate', n = 100)\n",
    "print(\"\\n\")\n",
    "print_column_narc_count(data,'riv','ai_hate', n = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "narc-twitter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
