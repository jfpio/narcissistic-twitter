{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of words baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression \n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_type = 'post_travel'\n",
    "data_path = '../data/split/train.csv'\n",
    "test_data_path = '../data/split/test.csv'\n",
    "narcism_type = 'adm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_travel</th>\n",
       "      <th>post_abortion</th>\n",
       "      <th>adm</th>\n",
       "      <th>riv</th>\n",
       "      <th>gender</th>\n",
       "      <th>gender_3_text</th>\n",
       "      <th>age</th>\n",
       "      <th>ethnic_background</th>\n",
       "      <th>ethnic_background_8_text</th>\n",
       "      <th>education</th>\n",
       "      <th>...</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>twitter</th>\n",
       "      <th>none</th>\n",
       "      <th>facebook</th>\n",
       "      <th>instagram</th>\n",
       "      <th>tiktok</th>\n",
       "      <th>linkedin</th>\n",
       "      <th>pinterest</th>\n",
       "      <th>other</th>\n",
       "      <th>other_portals_7_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I wish I could travel 24/7 and get paid for it</td>\n",
       "      <td>This is a horrible time to be alive, when wome...</td>\n",
       "      <td>1.444</td>\n",
       "      <td>1.111</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Vacations are pricey these days but so worth i...</td>\n",
       "      <td>Safe sex will always be the best option. The g...</td>\n",
       "      <td>3.889</td>\n",
       "      <td>1.111</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Black African</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I recently visited beautiful Stratford upon Av...</td>\n",
       "      <td>I am very strongly apposed against the abortio...</td>\n",
       "      <td>3.444</td>\n",
       "      <td>2.667</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I have just visited Marrakesh.The scenery is l...</td>\n",
       "      <td>Abortion is an emotive subject but a total ban...</td>\n",
       "      <td>3.667</td>\n",
       "      <td>2.889</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I travel a lot for work, and I get to see all ...</td>\n",
       "      <td>This is fucking stupid and scary. Restricting ...</td>\n",
       "      <td>1.222</td>\n",
       "      <td>1.222</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>reddit</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         post_travel  \\\n",
       "0     I wish I could travel 24/7 and get paid for it   \n",
       "1  Vacations are pricey these days but so worth i...   \n",
       "2  I recently visited beautiful Stratford upon Av...   \n",
       "3  I have just visited Marrakesh.The scenery is l...   \n",
       "4  I travel a lot for work, and I get to see all ...   \n",
       "\n",
       "                                       post_abortion    adm    riv  gender  \\\n",
       "0  This is a horrible time to be alive, when wome...  1.444  1.111     2.0   \n",
       "1  Safe sex will always be the best option. The g...  3.889  1.111     1.0   \n",
       "2  I am very strongly apposed against the abortio...  3.444  2.667     2.0   \n",
       "3  Abortion is an emotive subject but a total ban...  3.667  2.889     1.0   \n",
       "4  This is fucking stupid and scary. Restricting ...  1.222  1.222     1.0   \n",
       "\n",
       "  gender_3_text  age  ethnic_background ethnic_background_8_text  education  \\\n",
       "0           NaN   33                1.0                      NaN        2.0   \n",
       "1           NaN   27                8.0            Black African        2.0   \n",
       "2           NaN   41                1.0                      NaN        1.0   \n",
       "3           NaN   65                1.0                      NaN        5.0   \n",
       "4           NaN   30                1.0                      NaN        4.0   \n",
       "\n",
       "   ...  marital_status  twitter none  facebook  instagram  tiktok  linkedin  \\\n",
       "0  ...             4.0      6.0  NaN       1.0        1.0     1.0       1.0   \n",
       "1  ...             5.0      1.0  NaN       1.0        1.0     1.0       1.0   \n",
       "2  ...             5.0      1.0  NaN       1.0        1.0     1.0       1.0   \n",
       "3  ...             1.0      2.0  1.0       NaN        NaN     NaN       NaN   \n",
       "4  ...             5.0      2.0  NaN       1.0        NaN     NaN       NaN   \n",
       "\n",
       "   pinterest  other  other_portals_7_text  \n",
       "0        NaN    NaN                   NaN  \n",
       "1        NaN    NaN                   NaN  \n",
       "2        1.0    NaN                   NaN  \n",
       "3        NaN    NaN                   NaN  \n",
       "4        NaN    1.0                reddit  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the data\n",
    "data = pd.read_csv(data_path)\n",
    "test_data = pd.read_csv(test_data_path)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10</th>\n",
       "      <th>14</th>\n",
       "      <th>15mins</th>\n",
       "      <th>1980s</th>\n",
       "      <th>20</th>\n",
       "      <th>24</th>\n",
       "      <th>30</th>\n",
       "      <th>50</th>\n",
       "      <th>70</th>\n",
       "      <th>80</th>\n",
       "      <th>...</th>\n",
       "      <th>years</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>yet</th>\n",
       "      <th>york</th>\n",
       "      <th>you</th>\n",
       "      <th>young</th>\n",
       "      <th>your</th>\n",
       "      <th>yourself</th>\n",
       "      <th>zen</th>\n",
       "      <th>narcissism</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.475189</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.120431</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.184670</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 901 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    10   14  15mins  1980s   20        24   30   50   70   80  ...  years  \\\n",
       "0  0.0  0.0     0.0    0.0  0.0  0.475189  0.0  0.0  0.0  0.0  ...    0.0   \n",
       "1  0.0  0.0     0.0    0.0  0.0  0.000000  0.0  0.0  0.0  0.0  ...    0.0   \n",
       "2  0.0  0.0     0.0    0.0  0.0  0.000000  0.0  0.0  0.0  0.0  ...    0.0   \n",
       "3  0.0  0.0     0.0    0.0  0.0  0.000000  0.0  0.0  0.0  0.0  ...    0.0   \n",
       "4  0.0  0.0     0.0    0.0  0.0  0.000000  0.0  0.0  0.0  0.0  ...    0.0   \n",
       "\n",
       "   yesterday  yet  york       you  young  your  yourself  zen  narcissism  \n",
       "0        0.0  0.0   0.0  0.000000    0.0   0.0       0.0  0.0       1.444  \n",
       "1        0.0  0.0   0.0  0.120431    0.0   0.0       0.0  0.0       3.889  \n",
       "2        0.0  0.0   0.0  0.000000    0.0   0.0       0.0  0.0       3.444  \n",
       "3        0.0  0.0   0.0  0.184670    0.0   0.0       0.0  0.0       3.667  \n",
       "4        0.0  0.0   0.0  0.000000    0.0   0.0       0.0  0.0       1.222  \n",
       "\n",
       "[5 rows x 901 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vectorize the train data\n",
    "vectorizer = CountVectorizer()\n",
    "transformer = TfidfTransformer()\n",
    "counts = vectorizer.fit_transform(data[post_type].values)\n",
    "tfidf = transformer.fit_transform(counts)\n",
    "\n",
    "df_counts = pd.DataFrame(tfidf.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "df_counts['narcissism'] = data[narcism_type]\n",
    "df_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10</th>\n",
       "      <th>14</th>\n",
       "      <th>15mins</th>\n",
       "      <th>1980s</th>\n",
       "      <th>20</th>\n",
       "      <th>24</th>\n",
       "      <th>30</th>\n",
       "      <th>50</th>\n",
       "      <th>70</th>\n",
       "      <th>80</th>\n",
       "      <th>...</th>\n",
       "      <th>years</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>yet</th>\n",
       "      <th>york</th>\n",
       "      <th>you</th>\n",
       "      <th>young</th>\n",
       "      <th>your</th>\n",
       "      <th>yourself</th>\n",
       "      <th>zen</th>\n",
       "      <th>narcissism</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 901 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    10   14  15mins  1980s   20   24   30   50   70   80  ...  years  \\\n",
       "0  0.0  0.0     0.0    0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0   \n",
       "1  0.0  0.0     0.0    0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0   \n",
       "2  0.0  0.0     0.0    0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0   \n",
       "3  0.0  0.0     0.0    0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0   \n",
       "4  0.0  0.0     0.0    0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0   \n",
       "\n",
       "   yesterday  yet  york  you  young  your  yourself  zen  narcissism  \n",
       "0        0.0  0.0   0.0  0.0    0.0   0.0       0.0  0.0       1.667  \n",
       "1        0.0  0.0   0.0  0.0    0.0   0.0       0.0  0.0       3.000  \n",
       "2        0.0  0.0   0.0  0.0    0.0   0.0       0.0  0.0       3.111  \n",
       "3        0.0  0.0   0.0  0.0    0.0   0.0       0.0  0.0       2.222  \n",
       "4        0.0  0.0   0.0  0.0    0.0   0.0       0.0  0.0       2.889  \n",
       "\n",
       "[5 rows x 901 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vectorize the test data\n",
    "counts = vectorizer.transform(test_data[post_type].values)\n",
    "tfidf = transformer.transform(counts)\n",
    "\n",
    "test_counts = pd.DataFrame(tfidf.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "test_counts['narcissism'] = test_data[narcism_type]\n",
    "test_counts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare diffrent models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(df_counts.iloc[:, :-1], df_counts.iloc[:,-1], test_size=0.2, random_state=42)\n",
    "\n",
    "X_train = df_counts.iloc[:, :-1]\n",
    "y_train = np.ravel(df_counts[['narcissism']])\n",
    "X_test = test_counts.iloc[:, :-1]\n",
    "y_test = np.ravel(test_counts[['narcissism']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, X_train, y_train):\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "def predict(model, X_test):\n",
    "    return model.predict(X_test)\n",
    "\n",
    "def evaluate(y_test, y_pred):\n",
    "    return mean_squared_error(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression MSE: 0.7768377376883937\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train the linear regression model\n",
    "model = LinearRegression()\n",
    "train_model(model, X_train, y_train)\n",
    "y_pred = predict(model, X_test)\n",
    "mse = evaluate(y_test, y_pred)\n",
    "print(f\"Linear Regression MSE: {mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP Regressor MSE: 0.9552830835984694\n"
     ]
    }
   ],
   "source": [
    "model = MLPRegressor(max_iter=800)\n",
    "train_model(model, X_train, y_train)\n",
    "y_pred = predict(model, X_test)\n",
    "mse = evaluate(y_test, y_pred)\n",
    "print(f\"MLP Regressor MSE: {mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVR MSE: 0.6405744977662071\n"
     ]
    }
   ],
   "source": [
    "best_model = SVR()\n",
    "train_model(best_model, X_train, y_train)\n",
    "y_pred = predict(best_model, X_test)\n",
    "mse = evaluate(y_test, y_pred)\n",
    "print(f\"SVR MSE: {mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest MSE: 0.7228626762434789\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestRegressor()\n",
    "train_model(model, X_train, y_train)\n",
    "y_pred = predict(model, X_test)\n",
    "mse = evaluate(y_test, y_pred)\n",
    "print(f\"Random Forest MSE: {mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree MSE: 1.3684048695652173\n"
     ]
    }
   ],
   "source": [
    "model = DecisionTreeRegressor()\n",
    "train_model(model, X_train, y_train)\n",
    "y_pred = predict(model, X_test)\n",
    "mse = evaluate(y_test, y_pred)\n",
    "print(f\"Decision Tree MSE: {mse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far the best effects give SVM and Random Forest, but also the simples solution has rather small MSE - LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing on some new data\n",
    "Generated by chat GPT 3.5 \n",
    "Prompt: *\"Write me a travel post for twitter\"*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embarking on an exhilarating adventure through the enchanting streets of Kyoto, Japan. ðŸŽŒ From the serene bamboo forests of Arashiyama to the historic temples of Kinkaku-ji and Fushimi Inari Taisha, every corner unveils a tale of tradition and tranquility. #Kyoto #TravelJapan =>\n",
      "narcism: 2.696610216764748\n",
      "Lost in the colorful labyrinth of Marrakech's bustling souks, where the scent of spices fills the air and vibrant textiles dance in the breeze. ðŸ•Œâœ¨ Exploring hidden riads, savoring tagine delights, and getting lost in the magic of Jardin Majorelle. #Marrakech #TravelGoals ðŸŒ´ðŸŒž =>\n",
      "narcism: 2.79216584649148\n"
     ]
    }
   ],
   "source": [
    "# Won't work with the current data\n",
    "\n",
    "new_data = [\"Embarking on an exhilarating adventure through the enchanting streets of Kyoto, Japan. ðŸŽŒ From the serene bamboo forests of Arashiyama to the historic temples of Kinkaku-ji and Fushimi Inari Taisha, every corner unveils a tale of tradition and tranquility. #Kyoto #TravelJapan\", \"Lost in the colorful labyrinth of Marrakech's bustling souks, where the scent of spices fills the air and vibrant textiles dance in the breeze. ðŸ•Œâœ¨ Exploring hidden riads, savoring tagine delights, and getting lost in the magic of Jardin Majorelle. #Marrakech #TravelGoals ðŸŒ´ðŸŒž\"]\n",
    "counts = vectorizer.transform(new_data)\n",
    "tfidf = transformer.transform(counts)\n",
    "df_tfidf = pd.DataFrame(tfidf.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "predicted = predict(best_model, df_tfidf)\n",
    "for doc, category in zip(new_data, predicted):\n",
    "     print(f'{doc} =>\\nnarcism: {category}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing it on data that is not talking about travel (the abortion posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVR MSE test_ab: 0.8148133279056374\n"
     ]
    }
   ],
   "source": [
    "counts = vectorizer.transform(data[\"post_abortion\"].values)\n",
    "tfidf = transformer.transform(counts)\n",
    "\n",
    "test_counts_ab = pd.DataFrame(tfidf.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "test_counts_ab['narcissism'] = data[narcism_type]\n",
    "X_test_ab = test_counts_ab.iloc[:, :-1]\n",
    "y_test_ab = np.ravel(test_counts_ab[['narcissism']])\n",
    "y_pred_ab = predict(best_model, X_test_ab)\n",
    "mse = evaluate(y_test_ab, y_pred_ab)\n",
    "print(f\"SVR MSE test_ab: {mse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is interesting that the model rather correctly predicts the 'ADM' narcissism in abortion posts despite being trained on different data. MSE is still less then 1 point (on the scale 1 to 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "narc-twitter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
