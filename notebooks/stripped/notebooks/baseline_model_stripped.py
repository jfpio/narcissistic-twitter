"""
# Bag of words baseline model
"""

import pandas as pd
import numpy as np
from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression 
from sklearn.neural_network import MLPRegressor
from sklearn.svm import SVR
from sklearn.ensemble import RandomForestRegressor
from sklearn.tree import DecisionTreeRegressor
from sklearn.metrics import mean_squared_error
from sklearn.pipeline import Pipeline
from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer


post_type = 'post_travel'
data_path = '../data/split/train.csv'
test_data_path = '../data/split/test.csv'
narcism_type = 'adm'


# Read the data
data = pd.read_csv(data_path)
test_data = pd.read_csv(test_data_path)
data.head()


# Create a pipeline that includes vectorization and transformation
preprocessing_pipeline = Pipeline([
    ('vectorizer', CountVectorizer()),
    ('tfidf', TfidfTransformer())
])

tfidf = preprocessing_pipeline.fit_transform(data[post_type].values)
df_counts = pd.DataFrame(tfidf.toarray())
df_counts['narcissism'] = data[narcism_type]

df_counts.head()


# Transform the test data
tfidf = preprocessing_pipeline.transform(test_data[post_type].values)
test_counts = pd.DataFrame(tfidf.toarray())
test_counts['narcissism'] = test_data[narcism_type]

test_counts.head()


"""
## Compare different models
"""

# Load split data
X_train = df_counts.iloc[:, :-1]
y_train = np.ravel(df_counts[['narcissism']])
X_test = test_counts.iloc[:, :-1]
y_test = np.ravel(test_counts[['narcissism']])


def train_model(model, X_train, y_train):
    model.fit(X_train, y_train)
    return model

def predict(model, X_test):
    return model.predict(X_test)

def evaluate(y_test, y_pred):
    return mean_squared_error(y_test, y_pred)


lr_model = LinearRegression()
train_model(lr_model, X_train, y_train)
y_pred = predict(lr_model, X_test)
mse = evaluate(y_test, y_pred)
print(f"Linear Regression MSE: {mse}")


mlpr_model = MLPRegressor(max_iter=800)
train_model(mlpr_model, X_train, y_train)
y_pred = predict(mlpr_model, X_test)
mse = evaluate(y_test, y_pred)
print(f"MLP Regressor MSE: {mse}")


svr_model = SVR()
train_model(svr_model, X_train, y_train)
y_pred = predict(svr_model, X_test)
mse = evaluate(y_test, y_pred)
print(f"SVR MSE: {mse}")


rfr_model = RandomForestRegressor()
train_model(rfr_model, X_train, y_train)
y_pred = predict(rfr_model, X_test)
mse = evaluate(y_test, y_pred)
print(f"Random Forest MSE: {mse}")


dtr_model = DecisionTreeRegressor()
train_model(dtr_model, X_train, y_train)
y_pred = predict(dtr_model, X_test)
mse = evaluate(y_test, y_pred)
print(f"Decision Tree MSE: {mse}")


"""
So far the best effects give SVM and Random Forest, but also the simples solution has rather small MSE - LinearRegression
"""

"""
## Testing on some new data
Generated by chat GPT 3.5 
Prompt: *"Write me a travel post for twitter"*
"""

# Choosing the best model based on the MSE
best_model = svr_model


# Won't work with the current data

new_data = ["Embarking on an exhilarating adventure through the enchanting streets of Kyoto, Japan. ðŸŽŒ From the serene bamboo forests of Arashiyama to the historic temples of Kinkaku-ji and Fushimi Inari Taisha, every corner unveils a tale of tradition and tranquility. #Kyoto #TravelJapan", "Lost in the colorful labyrinth of Marrakech's bustling souks, where the scent of spices fills the air and vibrant textiles dance in the breeze. ðŸ•Œâœ¨ Exploring hidden riads, savoring tagine delights, and getting lost in the magic of Jardin Majorelle. #Marrakech #TravelGoals ðŸŒ´ðŸŒž"]
preprocessed_data = preprocessing_pipeline.transform(new_data)
post_test = pd.DataFrame(preprocessed_data.toarray())
predicted = predict(best_model, post_test)
for doc, category in zip(new_data, predicted):
     print(f'{doc} =>\nnarcism: {category}')


"""
Testing it on data that is not talking about travel (the abortion posts)
"""

tfidf = preprocessing_pipeline.transform(data["post_abortion"].values)

test_counts_ab = pd.DataFrame(tfidf.toarray())
test_counts_ab['narcissism'] = data[narcism_type]
X_test_ab = test_counts_ab.iloc[:, :-1]
y_test_ab = np.ravel(test_counts_ab[['narcissism']])
y_pred_ab = predict(best_model, X_test_ab)
mse = evaluate(y_test_ab, y_pred_ab)
print(f"SVR MSE test_ab: {mse}")


"""
It is interesting that the model rather correctly predicts the 'ADM' narcissism in abortion posts despite being trained on different data. MSE is still less then 1 point (on the scale 1 to 6)
"""

